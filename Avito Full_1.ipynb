{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.similarities.docsim import Similarity\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk.data\n",
    "import string\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import matutils\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iteminfo_train = pd.read_csv('ItemInfo_train.csv')\n",
    "#iteminfo_test = pd.read_csv('ItemInfo_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itempairs_train = pd.read_csv('ItemPairs_train.csv')\n",
    "#itempairs_test = pd.read_csv('ItemPairs_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = pd.read_csv('Location.csv')\n",
    "category = pd.read_csv('Category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iteminfo_train_loc = pd.merge(pd.merge(iteminfo_train, location, how = 'left', on = 'locationID'), category, how = 'left', on = 'categoryID')\n",
    "#iteminfo_test_loc = pd.merge(pd.merge(iteminfo_test, location, how = 'left', on = 'locationID'), category, how = 'left', on = 'categoryID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.merge(pd.merge(itempairs_train, iteminfo_train_loc, how = 'left', left_on = 'itemID_1', right_on = 'itemID'), \n",
    "                    iteminfo_train_loc, how = 'left', left_on = 'itemID_2', right_on = 'itemID')\n",
    "#x_test = pd.merge(pd.merge(itempairs_test, iteminfo_test_loc, how = 'left', left_on = 'itemID_1', right_on = 'itemID'), \n",
    "#                    iteminfo_test_loc, how = 'left', left_on = 'itemID_2', right_on = 'itemID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['title_x'] = x.title_x.map(lambda x : '' if pd.isnull(x) else x)\n",
    "x['title_y'] = x.title_y.map(lambda x : '' if pd.isnull(x) else x)\n",
    "x['description_x'] = x.description_x.map(lambda x : '' if pd.isnull(x) else x)\n",
    "x['description_y'] = x.description_y.map(lambda x : '' if pd.isnull(x) else x)\n",
    "#x_test['title_x'] = x_test.title_x.map(lambda x : '' if pd.isnull(x) else x)\n",
    "#x_test['title_y'] = x_test.title_y.map(lambda x : '' if pd.isnull(x) else x)\n",
    "#x_test['description_x'] = x_test.description_x.map(lambda x : '' if pd.isnull(x) else x)\n",
    "#x_test['description_y'] = x_test.description_y.map(lambda x : '' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4oAAAFpCAYAAADawtb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3a7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x['price_diff'] = abs(x.price_x - x.price_y).map(lambda x : 0 if np.isnan(x) else 0 if x == 0 else math.log(x))\n",
    "figure = plt.figure(figsize=(15,6))\n",
    "plt.hist(x.price_diff, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15,6))\n",
    "plt.hist(np.array(x.price_diff)[np.where(x.price_diff != 0)], bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "Finding difference in number of images between the two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['images_array_x'] =  x['images_array_x'].apply(lambda s : len(s.split()) if isinstance(s, str) else 0)\n",
    "x['images_array_y'] =  x['images_array_y'].apply(lambda s : len(s.split()) if isinstance(s, str) else 0)\n",
    "x['images_num_diff'] = x[['images_array_x', 'images_array_y']].apply(lambda s: abs(s[0] - s[1]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.groupby('images_num_diff').count()['itemID_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15,6))\n",
    "images_num_diff_counts = x.groupby('images_num_diff').count()['itemID_1']\n",
    "plt.bar(range(len(images_num_diff_counts)), images_num_diff_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['region_dist'] = abs(x.regionID_x - x.regionID_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x['loc_dist'] = np.abs(x['lat_x']-x['lat_y']) + np.abs(x['lon_x']-x['lon_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(document):    \n",
    "    # Removes punctuations\n",
    "    document = document.translate(string.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    \n",
    "    # Change to lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Removes newline characters\n",
    "    document = ' '.join(document.split('\\n'))\n",
    "    \n",
    "    # Replace multiple spaces with one space\n",
    "    document = ' '.join(document.split())\n",
    "    #document = nlp(unicode(document))\n",
    "    \n",
    "    return document\n",
    "\n",
    "def word_vec(x, model, num_features):\n",
    "    try:\n",
    "        a = model[x]\n",
    "        b = 1\n",
    "    except KeyError:\n",
    "        a = np.zeros(num_features)\n",
    "        b = 0\n",
    "    return [a,b]\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    \n",
    "    for word in words:\n",
    "        a, b = word_vec(word, model, num_features)\n",
    "        nwords = nwords + b\n",
    "        featureVec = np.add(featureVec, a)\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords != 0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec\n",
    "sentences_desc_x = []\n",
    "sentences_desc_y = []\n",
    "for i in range(len(x.description_x)):\n",
    "    if i in [10, 500000, 1000000, 1500000, 2000000]:\n",
    "        print i\n",
    "    sentences_desc_x.append(clean_text(x.description_x[i]))\n",
    "    sentences_desc_y.append(clean_text(x.description_y[i]))\n",
    "pd.DataFrame(sentences_desc_x, columns = ['sentences_desc_x']).to_csv('sentences_desc_x.csv')\n",
    "pd.DataFrame(sentences_desc_y, columns = ['sentences_desc_y']).to_csv('sentences_desc_y.csv')\n",
    "del sentences_desc_x\n",
    "del sentences_desc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "sentences_title_x = []\n",
    "sentences_title_y = []\n",
    "for i in range(len(x.title_x)):\n",
    "    if i in [10, 500000, 1000000, 1500000, 2000000]:\n",
    "        print i\n",
    "    sentences_title_x.append(clean_text(x.title_x[i]))\n",
    "    sentences_title_y.append(clean_text(x.title_y[i]))\n",
    "pd.DataFrame(sentences_title_x, columns = ['sentences_title_x']).to_csv('sentences_title_x.csv')\n",
    "pd.DataFrame(sentences_title_y, columns = ['sentences_title_y']).to_csv('sentences_title_y.csv')\n",
    "del sentences_title_x\n",
    "del sentences_title_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x = pd.DataFrame(np.column_stack([x.images_num_diff, x.price_diff, x.parentCategoryID_x, x.isDuplicate, x.loc_dist, x.region_dist]), columns = ['images_num_diff', 'price_diff', 'parentCategoryID_x', 'isDuplicate', 'loc_dist', 'region_dist'])\n",
    "new_x.to_csv('new_x.csv')\n",
    "del new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_desc_x = pd.read_csv('sentences_desc_x.csv')\n",
    "sentences_desc_y = pd.read_csv('sentences_desc_y.csv')\n",
    "sentences_title_x = pd.read_csv('sentences_title_x.csv')\n",
    "sentences_title_y = pd.read_csv('sentences_title_y.csv')\n",
    "x = pd.read_csv('new_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sentences_desc_x['Unnamed: 0']\n",
    "del sentences_desc_y['Unnamed: 0']\n",
    "del sentences_title_x['Unnamed: 0']\n",
    "del sentences_title_y['Unnamed: 0']\n",
    "del x['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, random_state = 1)\n",
    "train_score = []\n",
    "test_score = []\n",
    "log_reg = LogisticRegression()\n",
    "i = 0\n",
    "sentences_desc_x = np.array(sentences_desc_x.sentences_desc_x.map(lambda x : x.split() if isinstance(x, basestring) else str(x)))\n",
    "sentences_desc_y = np.array(sentences_desc_y.sentences_desc_y.map(lambda x : x.split() if isinstance(x, basestring) else str(x)))\n",
    "sentences_title_x = np.array(sentences_title_x.sentences_title_x.map(lambda x : x.split() if isinstance(x, basestring) else str(x)))\n",
    "sentences_title_y = np.array(sentences_title_y.sentences_title_y.map(lambda x : x.split() if isinstance(x, basestring) else str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index, test_index = list(kf.split(x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_desc_x_train = sentences_desc_x[train_index]\n",
    "sentences_desc_y_train = sentences_desc_y[train_index]\n",
    "sentences_desc_x_test = sentences_desc_x[test_index]\n",
    "sentences_desc_y_test = sentences_desc_y[test_index]\n",
    "sentences_title_x_train = sentences_title_x[train_index]\n",
    "sentences_title_y_train = sentences_title_y[train_index]\n",
    "sentences_title_x_test = sentences_title_x[test_index]\n",
    "sentences_title_y_test = sentences_title_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_corpus = np.concatenate((sentences_desc_x_train, sentences_desc_y_train, sentences_title_x_train, sentences_title_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training w2v\n"
     ]
    }
   ],
   "source": [
    "print 'Training w2v'\n",
    "model = Word2Vec(training_corpus, min_count = 1, size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x.loc[train_index, :].reset_index(drop = True), x.loc[test_index, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('w2v_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('w2v_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing training similarity\n",
      "10\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "1224282\n",
      "2393116\n",
      "0.51158489601\n"
     ]
    }
   ],
   "source": [
    "print 'computing training similarity'\n",
    "cos_sim_desc = []\n",
    "cos_sim_title = []\n",
    "trainDuplicate = []\n",
    "for i in range(len(sentences_desc_x_train)):\n",
    "    if i in [10, 500000, 1000000, 1500000, 2000000]:\n",
    "        print i\n",
    "    value_desc = model.wv.n_similarity(sentences_desc_x_train[i], sentences_desc_y_train[i])\n",
    "    value_title = model.wv.n_similarity(sentences_title_x_train[i], sentences_title_y_train[i])\n",
    "    cos_sim_desc.append(value_desc)\n",
    "    cos_sim_title.append(value_title)\n",
    "    if value_desc >= 0.5 and value_title >= 0.5:\n",
    "        if x_train.isDuplicate[i] == 1.0:\n",
    "            trainDuplicate.append(1)\n",
    "        else:\n",
    "            trainDuplicate.append(0)\n",
    "    else:\n",
    "        if x_train.isDuplicate[i] == 0.0:\n",
    "            trainDuplicate.append(1)\n",
    "        else:\n",
    "            trainDuplicate.append(0)\n",
    "print trainDuplicate.count(1)\n",
    "print len(trainDuplicate)\n",
    "print float(trainDuplicate.count(1)) / len(trainDuplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vocab = set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_word_vec(sent, model_vocab = model_vocab):\n",
    "    final_sent = []\n",
    "    for word in sent:\n",
    "        if word in model_vocab:\n",
    "            final_sent.append(word)\n",
    "    return final_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "500000\n",
      "305384\n",
      "598280\n",
      "0.510436584877\n"
     ]
    }
   ],
   "source": [
    "cos_sim_desc_test = []\n",
    "cos_sim_title_test = []\n",
    "testDuplicate = []\n",
    "for i in range(len(sentences_desc_x_test)):\n",
    "    if i in [10, 500000, 1000000, 1500000, 2000000]:\n",
    "        print i\n",
    "    sentences_desc_x_testa = check_word_vec(sentences_desc_x_test[i])\n",
    "    sentences_desc_y_testa = check_word_vec(sentences_desc_y_test[i])\n",
    "    sentences_title_x_testa = check_word_vec(sentences_title_x_test[i])\n",
    "    sentences_title_y_testa = check_word_vec(sentences_title_y_test[i])\n",
    "    if len(sentences_desc_x_testa) and len(sentences_desc_y_testa):\n",
    "        value_desc = model.wv.n_similarity(sentences_desc_x_testa, sentences_desc_y_testa)\n",
    "    if len(sentences_title_x_testa) and len(sentences_title_y_testa):\n",
    "        value_title = model.wv.n_similarity(sentences_title_x_testa, sentences_title_y_testa)\n",
    "    cos_sim_desc_test.append(value_desc)\n",
    "    cos_sim_title_test.append(value_title)\n",
    "    if value_desc >= 0.5 and value_title >= 0.5:\n",
    "        if x_test.isDuplicate[i] == 1.0:\n",
    "            testDuplicate.append(1)\n",
    "        else:\n",
    "            testDuplicate.append(0)\n",
    "    else:\n",
    "        if x_test.isDuplicate[i] == 0.0:\n",
    "            testDuplicate.append(1)\n",
    "        else:\n",
    "            testDuplicate.append(0)\n",
    "print testDuplicate.count(1)\n",
    "print len(testDuplicate)\n",
    "print float(testDuplicate.count(1)) / len(testDuplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_sim_desc_train_df = pd.DataFrame(cos_sim_desc, columns = ['cos_sim_desc_train'])\n",
    "cos_sim_desc_test_df = pd.DataFrame(cos_sim_desc_test, columns = ['cos_sim_desc_test'])\n",
    "cos_sim_title_train_df = pd.DataFrame(cos_sim_title, columns = ['cos_sim_title_train'])\n",
    "cos_sim_title_test_df = pd.DataFrame(cos_sim_title_test, columns = ['cos_sim_title_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.concat([x_train, cos_sim_desc_train_df, cos_sim_title_train_df], axis = 1)\n",
    "x_test = pd.concat([x_test, cos_sim_desc_test_df, cos_sim_title_test_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.676868690245\n",
      "Train Accuracy: 0.676090920791\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, random_state = 1)\n",
    "train_score = []\n",
    "test_score = []\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train.iloc[:, x_train.columns != 'isDuplicate'], np.array(x_train.isDuplicate))\n",
    "pred_train = log_reg.predict(x_train.iloc[:, x_train.columns != 'isDuplicate'])\n",
    "pred_test = log_reg.predict(x_test.iloc[:, x_test.columns != 'isDuplicate'])\n",
    "train_score.append(pred_train)\n",
    "test_score.append(pred_test)\n",
    "print \"Test Accuracy:\", accuracy_score(x_test.isDuplicate, pred_test)\n",
    "print \"Train Accuracy:\", accuracy_score(x_train.isDuplicate, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
